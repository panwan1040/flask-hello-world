#!/usr/bin/env python3
"""
YOLO Object Detection Web App
‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Camera ‡πÅ‡∏•‡∏∞ File Upload
‡πÉ‡∏ä‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•: runs/detect/train7/weights/best.pt
"""

from flask import Flask, Response, render_template_string, request, jsonify
import cv2
import numpy as np
from ultralytics import YOLO
import threading
import time
import os
import base64
from io import BytesIO
from PIL import Image

app = Flask(__name__)

# Global variables
model = None
camera = None
output_frame = None
lock = threading.Lock()

# Detection settings
CONFIDENCE_THRESHOLD = 0.95  # 95% confidence threshold
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}

# ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå upload ‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ
if not os.path.exists(UPLOAD_FOLDER):
    os.makedirs(UPLOAD_FOLDER)

# HTML Template
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="th">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>YOLO Object Detection - Camera</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: white;
        }
        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(10px);
            box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
        }
        h1 {
            text-align: center;
            margin-bottom: 30px;
            font-size: 2.5em;
            text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
        }
        .video-container {
            display: flex;
            justify-content: center;
            margin: 20px 0;
        }
        #video-stream {
            border-radius: 15px;
            box-shadow: 0 8px 32px rgba(0,0,0,0.3);
            max-width: 100%;
            height: auto;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        .settings {
            display: flex;
            justify-content: center;
            gap: 30px;
            margin: 20px 0;
            flex-wrap: wrap;
        }
        .setting-group {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            min-width: 250px;
        }
        .setting-group label {
            display: block;
            margin-bottom: 10px;
            font-weight: bold;
            color: #FFD93D;
        }
        .setting-group input[type="range"] {
            width: 100%;
            margin: 10px 0;
        }
        .setting-group .value-display {
            font-size: 1.2em;
            font-weight: bold;
            color: #4ECDC4;
            margin-top: 10px;
        }
        button {
            background: linear-gradient(45deg, #FF6B6B, #4ECDC4);
            border: none;
            padding: 15px 30px;
            border-radius: 25px;
            color: white;
            font-size: 16px;
            font-weight: bold;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        }
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 20px rgba(0,0,0,0.3);
        }
        button:active {
            transform: translateY(0);
        }
        .status {
            text-align: center;
            margin: 20px 0;
            padding: 15px;
            border-radius: 10px;
            background: rgba(255, 255, 255, 0.1);
        }
        .stats {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .stat-card {
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 15px;
            text-align: center;
            backdrop-filter: blur(5px);
        }
        .stat-number {
            font-size: 2em;
            font-weight: bold;
            color: #FFD93D;
        }
        .stat-label {
            font-size: 0.9em;
            opacity: 0.8;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéØ YOLO Object Detection</h1>

        <div class="video-container">
            <!-- Camera Mode -->
            <div id="camera-mode" style="display: block;">
                <img id="video-stream" src="/video_feed" alt="Video Stream">
            </div>

            <!-- Upload Mode -->
            <div id="upload-mode" style="display: none;">
                <div id="upload-result" style="display: none;">
                    <img id="result-image" src="" alt="Detection Result" style="max-width: 100%; border-radius: 15px; box-shadow: 0 8px 32px rgba(0,0,0,0.3);">
                </div>
                <div id="upload-placeholder" style="text-align: center; padding: 50px; background: rgba(255,255,255,0.1); border-radius: 15px; border: 2px dashed rgba(255,255,255,0.3);">
                    <div style="font-size: 3em; margin-bottom: 20px;">üì∏</div>
                    <div style="font-size: 1.2em; margin-bottom: 20px;">‡∏•‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏°‡∏≤‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà ‡∏´‡∏£‡∏∑‡∏≠‡∏Ñ‡∏•‡∏¥‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå</div>
                    <input type="file" id="file-input" accept="image/*" style="display: none;">
                    <button onclick="document.getElementById('file-input').click()" style="background: linear-gradient(45deg, #FF6B6B, #4ECDC4); border: none; padding: 15px 30px; border-radius: 25px; color: white; font-size: 16px; font-weight: bold; cursor: pointer;">‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û</button>
                </div>
            </div>
        </div>

        <div class="controls">
            <button onclick="switchMode('camera')">üìπ ‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á</button>
            <button onclick="switchMode('upload')">üì∏ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û</button>
            <button onclick="startDetection()">‚ñ∂Ô∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö</button>
            <button onclick="stopDetection()">‚èπÔ∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö</button>
            <button onclick="toggleFullscreen()">üîç ‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≠</button>
        </div>

        <div class="settings">
            <div class="setting-group">
                <label for="confidence-slider">üéØ ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö</label>
                <input type="range" id="confidence-slider" min="0.1" max="1.0" step="0.05" value="0.95">
                <div class="value-display" id="confidence-value">95%</div>
            </div>
        </div>

        <div class="status" id="status">
            ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO...
        </div>

        <div class="stats">
            <div class="stat-card">
                <div class="stat-number" id="fps">0</div>
                <div class="stat-label">FPS</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="objects">0</div>
                <div class="stat-label">‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö</div>
            </div>
            <div class="stat-card">
                <div class="stat-number" id="confidence">0%</div>
                <div class="stat-label">‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢</div>
            </div>
        </div>
    </div>

    <script>
        let detectionActive = false;
        let fpsCounter = 0;
        let fpsTimer = Date.now();
        let currentMode = 'camera';

        function switchMode(mode) {
            currentMode = mode;
            const cameraMode = document.getElementById('camera-mode');
            const uploadMode = document.getElementById('upload-mode');
            const uploadResult = document.getElementById('upload-result');
            const uploadPlaceholder = document.getElementById('upload-placeholder');

            if (mode === 'camera') {
                cameraMode.style.display = 'block';
                uploadMode.style.display = 'none';
                document.getElementById('status').innerHTML = 'üìπ ‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á - ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠...';
            } else {
                cameraMode.style.display = 'none';
                uploadMode.style.display = 'block';
                uploadResult.style.display = 'none';
                uploadPlaceholder.style.display = 'block';
                document.getElementById('status').innerHTML = 'üì∏ ‡πÇ‡∏´‡∏°‡∏î‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î - ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏';
                document.getElementById('status').style.background = 'rgba(76, 237, 196, 0.2)';
            }
        }

        function startDetection() {
            detectionActive = true;
            if (currentMode === 'camera') {
                document.getElementById('status').innerHTML = 'üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏...';
            }
            document.getElementById('status').style.background = 'rgba(76, 237, 196, 0.2)';
        }

        function stopDetection() {
            detectionActive = false;
            document.getElementById('status').innerHTML = '‚è∏Ô∏è ‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö';
            document.getElementById('status').style.background = 'rgba(255, 107, 107, 0.2)';
        }

        function toggleFullscreen() {
            const video = document.getElementById('video-stream');
            if (!document.fullscreenElement) {
                video.requestFullscreen().catch(err => {
                    console.log('Error attempting to enable fullscreen:', err);
                });
            } else {
                document.exitFullscreen();
            }
        }

        // Update stats every second
        setInterval(() => {
            fetch('/stats')
                .then(response => response.json())
                .then(data => {
                    document.getElementById('fps').textContent = data.fps;
                    document.getElementById('objects').textContent = data.objects;
                    document.getElementById('confidence').textContent = (data.confidence * 100).toFixed(1) + '%';
                })
                .catch(err => console.log('Error fetching stats:', err));
        }, 1000);

        // Check model status
        setInterval(() => {
            fetch('/status')
                .then(response => response.json())
                .then(data => {
                    if (data.model_loaded) {
                        document.getElementById('status').innerHTML = '‚úÖ ‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô';
                        document.getElementById('status').style.background = 'rgba(76, 237, 196, 0.2)';
                    }
                });
        }, 2000);

        // Load initial confidence value
        fetch('/get_confidence')
            .then(response => response.json())
            .then(data => {
                const slider = document.getElementById('confidence-slider');
                const valueDisplay = document.getElementById('confidence-value');
                slider.value = data.confidence;
                valueDisplay.textContent = (data.confidence * 100).toFixed(1) + '%';
            });

        // Handle confidence slider change
        document.getElementById('confidence-slider').addEventListener('input', function() {
            const value = parseFloat(this.value);
            const valueDisplay = document.getElementById('confidence-value');
            valueDisplay.textContent = (value * 100).toFixed(1) + '%';

            // Send new confidence value to server
            fetch(`/set_confidence/${value}`)
                .then(response => response.json())
                .then(data => {
                    console.log('Confidence updated:', data.confidence);
                })
                .catch(err => console.log('Error updating confidence:', err));
        });

        // Handle file upload
        document.getElementById('file-input').addEventListener('change', function(e) {
            const file = e.target.files[0];
            if (file) {
                uploadAndDetect(file);
            }
        });

        // Handle drag and drop
        const uploadPlaceholder = document.getElementById('upload-placeholder');
        uploadPlaceholder.addEventListener('dragover', function(e) {
            e.preventDefault();
            this.style.background = 'rgba(76, 237, 196, 0.2)';
        });

        uploadPlaceholder.addEventListener('dragleave', function(e) {
            e.preventDefault();
            this.style.background = 'rgba(255, 255, 255, 0.1)';
        });

        uploadPlaceholder.addEventListener('drop', function(e) {
            e.preventDefault();
            this.style.background = 'rgba(255, 255, 255, 0.1)';

            const files = e.dataTransfer.files;
            if (files.length > 0) {
                const file = files[0];
                if (file.type.startsWith('image/')) {
                    uploadAndDetect(file);
                } else {
                    alert('‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô');
                }
            }
        });

        function uploadAndDetect(file) {
            const formData = new FormData();
            formData.append('file', file);

            document.getElementById('status').innerHTML = '‚è≥ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏...';
            document.getElementById('status').style.background = 'rgba(255, 193, 7, 0.2)';

            fetch('/upload', {
                method: 'POST',
                body: formData
            })
            .then(response => response.json())
            .then(data => {
                if (data.success) {
                    // ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                    document.getElementById('upload-placeholder').style.display = 'none';
                    document.getElementById('upload-result').style.display = 'block';
                    document.getElementById('result-image').src = 'data:image/jpeg;base64,' + data.image;

                    // ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                    document.getElementById('objects').textContent = data.objects;
                    document.getElementById('confidence').textContent = (data.confidence * 100).toFixed(1) + '%';

                    document.getElementById('status').innerHTML = '‚úÖ ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!';
                    document.getElementById('status').style.background = 'rgba(76, 237, 196, 0.2)';
                } else {
                    throw new Error(data.error);
                }
            })
            .catch(error => {
                console.error('Upload error:', error);
                document.getElementById('status').innerHTML = '‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: ' + error.message;
                document.getElementById('status').style.background = 'rgba(255, 107, 107, 0.2)';
            });
        }
    </script>
</body>
</html>
"""

def allowed_file(filename):
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ô‡∏≤‡∏°‡∏™‡∏Å‡∏∏‡∏•‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def load_model():
    """‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO"""
    global model
    try:
        # ‡∏•‡∏≠‡∏á‡∏´‡∏•‡∏≤‡∏¢‡πÜ path ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö online deployment
        possible_paths = [
            r"D:\code project\Part-Counter.v1i.yolov8\runs\detect\train7\weights\best.pt",
            "runs/detect/train7/weights/best.pt",
            "./runs/detect/train7/weights/best.pt",
            "best.pt"
        ]

        model_path = None
        for path in possible_paths:
            if os.path.exists(path):
                model_path = path
                break

        if model_path is None:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLO")
            return False

        print(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏à‡∏≤‡∏Å: {model_path}")
        model = YOLO(model_path)
        print("‚úÖ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        return True
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•: {e}")
        return False

def initialize_camera():
    """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á"""
    global camera
    try:
        camera = cv2.VideoCapture(0)
        if not camera.isOpened():
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ")
            return False

        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏∏‡∏ì‡∏†‡∏≤‡∏û‡∏Å‡∏•‡πâ‡∏≠‡∏á
        camera.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        camera.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        camera.set(cv2.CAP_PROP_FPS, 30)

        print("‚úÖ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        return True
    except Exception as e:
        print(f"‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á: {e}")
        return False

def generate_frames():
    """‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÄ‡∏ü‡∏£‡∏°‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö streaming"""
    global output_frame, lock, model

    fps_counter = 0
    fps_timer = time.time()
    objects_detected = 0
    avg_confidence = 0.0

    while True:
        if camera is None:
            break

        success, frame = camera.read()
        if not success:
            break

        # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏î‡πâ‡∏ß‡∏¢ YOLO (confidence threshold 95%)
        if model is not None:
            try:
                results = model(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)

                # ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                annotated_frame = results[0].plot()

                # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢
                if len(results[0].boxes) > 0:
                    objects_detected = len(results[0].boxes)
                    confidences = results[0].boxes.conf.cpu().numpy()
                    avg_confidence = float(np.mean(confidences))
                else:
                    objects_detected = 0
                    avg_confidence = 0.0

                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì FPS
                fps_counter += 1
                current_time = time.time()
                if current_time - fps_timer >= 1.0:
                    fps = fps_counter / (current_time - fps_timer)
                    fps_counter = 0
                    fps_timer = current_time

                    # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥
                    with lock:
                        app.config['current_fps'] = round(fps, 1)
                        app.config['current_objects'] = objects_detected
                        app.config['current_confidence'] = avg_confidence

                frame = annotated_frame

            except Exception as e:
                print(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö: {e}")

        # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô JPEG
        ret, buffer = cv2.imencode('.jpg', frame)
        frame = buffer.tobytes()

        # ‡∏™‡πà‡∏á‡πÄ‡∏ü‡∏£‡∏°
        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')

@app.route('/')
def index():
    """‡∏´‡∏ô‡πâ‡∏≤‡πÅ‡∏£‡∏Å"""
    return render_template_string(HTML_TEMPLATE)

@app.route('/video_feed')
def video_feed():
    """Video streaming route"""
    return Response(generate_frames(),
                    mimetype='multipart/x-mixed-replace; boundary=frame')

@app.route('/status')
def get_status():
    """‡∏™‡πà‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡πÇ‡∏°‡πÄ‡∏î‡∏•"""
    return {
        'model_loaded': model is not None,
        'camera_active': camera is not None and camera.isOpened()
    }

@app.route('/stats')
def get_stats():
    """‡∏™‡πà‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    return {
        'fps': app.config.get('current_fps', 0),
        'objects': app.config.get('current_objects', 0),
        'confidence': app.config.get('current_confidence', 0.0)
    }

@app.route('/start_detection')
def start_detection():
    """‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    return {'status': 'started'}

@app.route('/stop_detection')
def stop_detection():
    """‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö"""
    return {'status': 'stopped'}

@app.route('/set_confidence/<float:confidence>')
def set_confidence(confidence):
    """‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ confidence threshold"""
    global CONFIDENCE_THRESHOLD
    CONFIDENCE_THRESHOLD = max(0.1, min(1.0, confidence))  # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á 0.1-1.0
    return {'status': 'success', 'confidence': CONFIDENCE_THRESHOLD}

@app.route('/get_confidence')
def get_confidence():
    """‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤ confidence threshold ‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"""
    return {'confidence': CONFIDENCE_THRESHOLD}

@app.route('/upload', methods=['POST'])
def upload_file():
    """‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏"""
    if 'file' not in request.files:
        return jsonify({'error': 'No file part'}), 400

    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'No selected file'}), 400

    if file and allowed_file(file.filename):
        try:
            # ‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏õ‡πá‡∏ô numpy array
            image = Image.open(file.stream)
            frame = np.array(image)

            # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            if frame.shape[-1] == 4:  # RGBA
                frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)
            elif len(frame.shape) == 2:  # Grayscale
                frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2RGB)

            # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
            if model is not None:
                results = model(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)
                annotated_frame = results[0].plot()

                # ‡∏™‡∏£‡πâ‡∏≤‡∏á base64 string ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö
                _, buffer = cv2.imencode('.jpg', cv2.cvtColor(annotated_frame, cv2.COLOR_RGB2BGR))
                img_str = base64.b64encode(buffer).decode('utf-8')

                # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
                objects_detected = len(results[0].boxes) if len(results[0].boxes) > 0 else 0
                avg_confidence = 0.0
                if objects_detected > 0:
                    confidences = results[0].boxes.conf.cpu().numpy()
                    avg_confidence = float(np.mean(confidences))

                return jsonify({
                    'success': True,
                    'image': img_str,
                    'objects': objects_detected,
                    'confidence': avg_confidence
                })
            else:
                return jsonify({'error': 'Model not loaded'}), 500

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    return jsonify({'error': 'Invalid file type'}), 400

def cleanup():
    """‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏ó‡∏£‡∏±‡∏û‡∏¢‡∏≤‡∏Å‡∏£"""
    global camera
    try:
        if camera is not None:
            camera.release()
            print("üîÑ ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡πâ‡∏ß")
    except Exception as e:
        print(f"‚ö†Ô∏è ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á: {e}")

if __name__ == '__main__':
    try:
        print("üöÄ ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÄ‡∏£‡∏¥‡πà‡∏° YOLO Object Detection Web App...")
        print("=" * 50)

        # ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•
        if not load_model():
            print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÑ‡∏î‡πâ ‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
            exit(1)

        # ‡∏û‡∏¢‡∏≤‡∏¢‡∏≤‡∏°‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á (‡πÑ‡∏°‡πà‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö online deployment)
        camera_available = initialize_camera()
        if camera_available:
            print("‚úÖ ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        else:
            print("‚ö†Ô∏è ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô (‡∏õ‡∏Å‡∏ï‡∏¥‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö online deployment)")

        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Flask
        app.config['current_fps'] = 0
        app.config['current_objects'] = 0
        app.config['current_confidence'] = 0.0

        print("‚úÖ ‡∏ó‡∏∏‡∏Å‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß!")
        print("üåê ‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå‡πÑ‡∏õ‡∏ó‡∏µ‡πà: http://localhost:5000")
        print("üì∏ ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û")
        if camera_available:
            print("üìπ ‡πÇ‡∏´‡∏°‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á: ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏•‡πÑ‡∏ó‡∏°‡πå")
        print("üí° ‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏¢‡∏∏‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        print("=" * 50)

        # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏ã‡∏¥‡∏£‡πå‡∏ü‡πÄ‡∏ß‡∏≠‡∏£‡πå
        app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000)), debug=False, threaded=True)

    except KeyboardInterrupt:
        print("\nüëã ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏¥‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°...")
    except Exception as e:
        print(f"\n‚ùå ‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
    finally:
        cleanup()
